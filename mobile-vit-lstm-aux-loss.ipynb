{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "babef1d7",
   "metadata": {
    "id": "44bca3ea",
    "outputId": "4c89f41c-0168-41db-fa8a-54c8d35a4cdb",
    "papermill": {
     "duration": 13.09359,
     "end_time": "2025-08-14T05:18:58.433893",
     "exception": false,
     "start_time": "2025-08-14T05:18:45.340303",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: jiwer in /opt/conda/lib/python3.11/site-packages (4.0.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /opt/conda/lib/python3.11/site-packages (from jiwer) (8.1.8)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /opt/conda/lib/python3.11/site-packages (from jiwer) (3.14.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2025.10.23)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2025.1.31)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (2.3.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (1.16.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.11/site-packages (0.17.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from peft) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft) (6.1.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft) (2.5.1+cu124)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from peft) (4.57.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from peft) (1.11.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from peft) (0.6.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /opt/conda/lib/python3.11/site-packages (from peft) (0.36.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2024.6.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub>=0.25.0->peft) (1.2.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (2025.10.23)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (0.22.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.1.31)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install jiwer\n",
    "!pip install matplotlib\n",
    "!pip install transformers\n",
    "# !pip install opencv-python\n",
    "# !pip install flash-attn --no-build-isolation\n",
    "!pip install --upgrade numpy scipy\n",
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57bca1fd",
   "metadata": {
    "id": "06ca011b",
    "outputId": "80b91c40-6016-4d3d-e0bf-5d5cef8139a6",
    "papermill": {
     "duration": 40.285532,
     "end_time": "2025-08-14T05:19:38.730889",
     "exception": false,
     "start_time": "2025-08-14T05:18:58.445357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.amp import autocast, GradScaler\n",
    "import torchvision\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "from transformers import AutoModel\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from jiwer import wer\n",
    "import peft\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077cd722",
   "metadata": {
    "id": "6cf41de8",
    "papermill": {
     "duration": 0.018107,
     "end_time": "2025-08-14T05:19:38.760338",
     "exception": false,
     "start_time": "2025-08-14T05:19:38.742231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_sequence(sequence, NUM_FRAMES):\n",
    "    columns = 4\n",
    "    rows = (NUM_FRAMES + 1) // (columns)\n",
    "    fig = plt.figure(figsize=(32, (16 // columns) * rows))\n",
    "    gs = gridspec.GridSpec(rows, columns)\n",
    "    for j in range(rows * columns):\n",
    "        plt.subplot(gs[j])\n",
    "        plt.axis(\"off\")\n",
    "        frames = sequence[j].permute(1,2,0).numpy()\n",
    "        frames = frames/ frames.max()\n",
    "        plt.imshow(frames)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec1b7014",
   "metadata": {
    "id": "cfd8dc14",
    "papermill": {
     "duration": 0.015534,
     "end_time": "2025-08-14T05:19:38.786624",
     "exception": false,
     "start_time": "2025-08-14T05:19:38.771090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb06495",
   "metadata": {
    "id": "d6450ee0",
    "papermill": {
     "duration": 0.015748,
     "end_time": "2025-08-14T05:19:38.812907",
     "exception": false,
     "start_time": "2025-08-14T05:19:38.797159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_csv = \"/home/jovyan/A_folder_so_its_cleaner/pheonix/phoenix/annotations/manual/train.corpus.csv\"\n",
    "test_csv = \"/home/jovyan/A_folder_so_its_cleaner/pheonix/phoenix/annotations/manual/test.corpus.csv\"\n",
    "dev_csv = \"/home/jovyan/A_folder_so_its_cleaner/pheonix/phoenix/annotations/manual/dev.corpus.csv\"\n",
    "\n",
    "train_paths = \"/home/jovyan/A_folder_so_its_cleaner/pheonix/phoenix/fullFrame-210x260px/train\"\n",
    "test_paths = \"/home/jovyan/A_folder_so_its_cleaner/pheonix/phoenix/fullFrame-210x260px/test\"\n",
    "dev_paths =  \"/home/jovyan/A_folder_so_its_cleaner/pheonix/phoenix/fullFrame-210x260px/dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b42991",
   "metadata": {
    "id": "f78d78a7",
    "papermill": {
     "duration": 0.015556,
     "end_time": "2025-08-14T05:19:38.838856",
     "exception": false,
     "start_time": "2025-08-14T05:19:38.823300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_frames = 96\n",
    "num_workers = 6\n",
    "batch_size = 2\n",
    "prefetch_factor = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7974d55",
   "metadata": {
    "id": "5e8e643c",
    "papermill": {
     "duration": 0.308303,
     "end_time": "2025-08-14T05:19:39.157882",
     "exception": false,
     "start_time": "2025-08-14T05:19:38.849579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_to_idx = { '<p>':0}\n",
    "idx_to_word = ['<p>']\n",
    "\n",
    "arr_train = np.loadtxt(train_csv, delimiter='|', dtype='str')\n",
    "arr_train = np.delete(arr_train,0,0)\n",
    "arr_test = np.loadtxt(test_csv, delimiter='|', dtype='str')\n",
    "arr_test = np.delete(arr_test,0,0)\n",
    "arr_dev = np.loadtxt(dev_csv, delimiter='|', dtype='str')\n",
    "arr_dev = np.delete(arr_dev,0,0)\n",
    "\n",
    "arr = np.concatenate((arr_train, arr_test, arr_dev), axis=0)\n",
    "\n",
    "for sentence in arr:\n",
    "    for word in sentence[3].split(' '):\n",
    "        if word not in idx_to_word:\n",
    "            idx_to_word.append(word)\n",
    "            word_to_idx[word] = len(idx_to_word)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17c933f8",
   "metadata": {
    "id": "240964dc",
    "outputId": "d7438424-30f9-4bbf-e8b4-357a896547a8",
    "papermill": {
     "duration": 0.017401,
     "end_time": "2025-08-14T05:19:39.186163",
     "exception": false,
     "start_time": "2025-08-14T05:19:39.168762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1297, 1297)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_to_word), len(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5be383c",
   "metadata": {
    "id": "04259044",
    "papermill": {
     "duration": 0.026054,
     "end_time": "2025-08-14T05:19:39.222913",
     "exception": false,
     "start_time": "2025-08-14T05:19:39.196859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class rwth_phoenix(Dataset):\n",
    "    def __init__(self, csv, data_path, frame_transform, video_transform, input_fps, output_fps, max_frames, stride, word_dict):\n",
    "\n",
    "        temp = np.loadtxt(csv, delimiter='|', dtype='str')\n",
    "        self.csv = np.delete(temp, 0, 0)\n",
    "        self.word_dict = word_dict\n",
    "        self.data_path = data_path\n",
    "\n",
    "        self.frame_transform = frame_transform\n",
    "        self.video_transform = video_transform\n",
    "\n",
    "        self.input_fps = input_fps\n",
    "        self.output_fps = output_fps\n",
    "        self.max_frames = max_frames\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        folder = self.csv[idx][1].split('/')\n",
    "        label = self.csv[idx][3].split(' ')\n",
    "\n",
    "        words = []\n",
    "        for word in label:\n",
    "            words.append(self.word_dict[word])\n",
    "        label = torch.tensor(words)\n",
    "        image_folder_path = os.path.join(self.data_path, folder[0], folder[1])\n",
    "\n",
    "        images = sorted(os.listdir(image_folder_path))\n",
    "        end = len(images)\n",
    "\n",
    "        step = self.input_fps/random.choice(self.output_fps)\n",
    "        image_list = []\n",
    "        if int(end//step +1) <= self.max_frames:\n",
    "            frame_num, num = 0, 0\n",
    "            while frame_num < end:\n",
    "                num+=1\n",
    "                if self.stride and num%self.stride == 0:\n",
    "                    image_list.append(str(int(frame_num))+'a')\n",
    "\n",
    "                else:\n",
    "                    img = Image.open(os.path.join(image_folder_path, images[int(frame_num)]))\n",
    "\n",
    "\n",
    "                    tensor_img = self.frame_transform(img)\n",
    "\n",
    "                    image_list.append(tensor_img)\n",
    "                frame_num += step\n",
    "\n",
    "            c, h, w = image_list[-1].shape\n",
    "            while len(image_list) < self.max_frames:\n",
    "                image_list.append(torch.zeros(c,h,w))\n",
    "\n",
    "            tensor_video = torch.stack(image_list[:self.max_frames])\n",
    "\n",
    "\n",
    "            if self.video_transform:\n",
    "                tensor_video = self.video_transform(tensor_video)\n",
    "\n",
    "\n",
    "        else:\n",
    "            frame_positions = np.linspace(0, end, self.max_frames, endpoint=False)\n",
    "            num = 0\n",
    "            for n in frame_positions:\n",
    "                num+=1\n",
    "                if self.stride and num%self.stride == 0:\n",
    "                    image_list.append(str(int(n))+'a')\n",
    "\n",
    "                else:\n",
    "                    img = Image.open(os.path.join(image_folder_path, images[int(n)]))\n",
    "\n",
    "\n",
    "                    tensor_img= self.frame_transform(img)\n",
    "                    image_list.append(tensor_img)\n",
    "\n",
    "            tensor_video = torch.stack(image_list[:self.max_frames])\n",
    "\n",
    "            if self.video_transform:\n",
    "                tensor_video = self.video_transform(tensor_video)\n",
    "            \n",
    "\n",
    "        \n",
    "        return tensor_video, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3651220c-9e89-4bcd-8764-dbb718dbbab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalRescale(object):\n",
    "    def __init__(self, temp_scaling=0.2):\n",
    "        self.min_len = 32\n",
    "        self.max_len = 230\n",
    "        self.L = 1.0 - temp_scaling\n",
    "        self.U = 1.0 + temp_scaling\n",
    "\n",
    "    def __call__(self, clip):\n",
    "        vid_len = len(clip)\n",
    "        new_len = int(vid_len * (self.L + (self.U - self.L) * np.random.random()))\n",
    "        if new_len < self.min_len:\n",
    "            new_len = self.min_len\n",
    "        if new_len > self.max_len:\n",
    "            new_len = self.max_len\n",
    "        if (new_len - 4) % 4 != 0:\n",
    "            new_len += 4 - (new_len - 4) % 4\n",
    "        if new_len <= vid_len:\n",
    "            index = sorted(random.sample(range(vid_len), new_len))\n",
    "        else:\n",
    "            index = sorted(random.choices(range(vid_len), k=new_len))\n",
    "        return clip[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d438ef80",
   "metadata": {
    "papermill": {
     "duration": 0.016859,
     "end_time": "2025-08-14T05:19:39.277949",
     "exception": false,
     "start_time": "2025-08-14T05:19:39.261090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "image_test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "video_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    TemporalRescale()\n",
    "])\n",
    "\n",
    "video_test_transform = transforms.Compose([\n",
    "    TemporalRescale(temp_scaling=0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0ee4b1d",
   "metadata": {
    "id": "612c2647",
    "papermill": {
     "duration": 0.016087,
     "end_time": "2025-08-14T05:19:39.304550",
     "exception": false,
     "start_time": "2025-08-14T05:19:39.288463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    vid, labels = zip(*batch)\n",
    "    \n",
    "    # Get video lengths before padding\n",
    "    vid_lengths = torch.tensor([v.shape[0] for v in vid])\n",
    "    \n",
    "    # Pad videos using pad_sequence\n",
    "    vid = torch.nn.utils.rnn.pad_sequence(\n",
    "        sequences=vid,\n",
    "        batch_first=True,\n",
    "        padding_value=0,\n",
    "    )\n",
    "    \n",
    "    # Pad labels\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(\n",
    "        sequences=labels,\n",
    "        batch_first=True,\n",
    "        padding_value=0,\n",
    "    ).long()\n",
    "    \n",
    "    return vid, labels, vid_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf539c71",
   "metadata": {
    "id": "e540a270",
    "papermill": {
     "duration": 0.062961,
     "end_time": "2025-08-14T05:19:39.378337",
     "exception": false,
     "start_time": "2025-08-14T05:19:39.315376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = rwth_phoenix(csv=train_csv,\n",
    "                       data_path=train_paths,\n",
    "                        frame_transform=image_transform , video_transform=video_transform, input_fps=25, output_fps=list(range(15,22)), max_frames=max_frames, stride=0, word_dict=word_to_idx)\n",
    "\n",
    "test_dataset = rwth_phoenix(csv=test_csv,\n",
    "                       data_path=test_paths,\n",
    "                        frame_transform=image_test_transform , video_transform=video_test_transform, input_fps=25, output_fps=list(range(15,22)), max_frames=max_frames, stride=0, word_dict=word_to_idx)\n",
    "\n",
    "dev_dataset = rwth_phoenix(csv=dev_csv,\n",
    "                       data_path=dev_paths,\n",
    "                        frame_transform=image_test_transform , video_transform=video_test_transform, input_fps=25, output_fps=list(range(15,22)), max_frames=max_frames, stride=0, word_dict=word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86639647",
   "metadata": {
    "id": "a54a5373",
    "papermill": {
     "duration": 0.01684,
     "end_time": "2025-08-14T05:19:39.406490",
     "exception": false,
     "start_time": "2025-08-14T05:19:39.389650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size, collate_fn=collate_fn, prefetch_factor=prefetch_factor, num_workers=num_workers, pin_memory=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, shuffle=False, batch_size=batch_size, collate_fn=collate_fn, prefetch_factor=prefetch_factor, num_workers=num_workers, pin_memory=True)\n",
    "dev_dataloader = DataLoader(dataset=dev_dataset, shuffle=False, batch_size=batch_size, collate_fn=collate_fn, prefetch_factor=prefetch_factor, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16c78afd",
   "metadata": {
    "id": "fa8b5e43",
    "papermill": {
     "duration": 0.015141,
     "end_time": "2025-08-14T05:19:39.432713",
     "exception": false,
     "start_time": "2025-08-14T05:19:39.417572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vid, kp_vid, y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b62bb90d",
   "metadata": {
    "id": "b70fde66",
    "outputId": "a63e7fbb-9c2a-4040-ee74-fad9faf7c510",
    "papermill": {
     "duration": 0.015812,
     "end_time": "2025-08-14T05:19:39.525694",
     "exception": false,
     "start_time": "2025-08-14T05:19:39.509882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68c1e686",
   "metadata": {
    "id": "955ed291",
    "outputId": "b7d29773-60ba-49c7-bfda-9a200bfb2161",
    "papermill": {
     "duration": 0.015254,
     "end_time": "2025-08-14T05:19:39.551660",
     "exception": false,
     "start_time": "2025-08-14T05:19:39.536406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show_sequence(vid[0], max_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc60029c",
   "metadata": {
    "papermill": {
     "duration": 0.01519,
     "end_time": "2025-08-14T05:19:39.577281",
     "exception": false,
     "start_time": "2025-08-14T05:19:39.562091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show_sequence(kp_vid[0], max_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f04dece0",
   "metadata": {
    "id": "38791323",
    "papermill": {
     "duration": 0.024959,
     "end_time": "2025-08-14T05:19:39.613331",
     "exception": false,
     "start_time": "2025-08-14T05:19:39.588372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = GradScaler('cuda')\n",
    "\n",
    "def update_length(lengths):\n",
    "    # return ((lengths - 4) // 2 - 4) // 2\n",
    "    return (lengths - 4) // 2\n",
    "\n",
    "def decode_pred(tensor, lengths, idx_to_word=idx_to_word):\n",
    "    n = tensor.shape[0]\n",
    "    text = []\n",
    "    for i in range(n):\n",
    "        st = []\n",
    "        prev_token = None\n",
    "        # Only iterate up to the actual length for this sequence\n",
    "        for j in range(lengths[i]):\n",
    "            token = tensor[i, j]\n",
    "            if token != 0 and token != prev_token:\n",
    "                st.append(idx_to_word[token.item()])\n",
    "            prev_token = token\n",
    "        text.append(' '.join(st))\n",
    "    return text\n",
    "\n",
    "def decode_target(tensor, idx_to_word=idx_to_word):\n",
    "    text = []\n",
    "    for seq in tensor:\n",
    "        words = [idx_to_word[token.item()] for token in seq if token.item() != 0]\n",
    "        text.append(' '.join(words))\n",
    "    return text\n",
    "\n",
    "def train_step(model, optimizer, dataloader, loss_fn, epoch, device=\"cuda\"):\n",
    "    model.train()\n",
    "    train_loss, total_correct_wer = 0, 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch}\", dynamic_ncols=True)\n",
    "    \n",
    "    for batch_idx, (X, y, lengths) in enumerate(progress_bar):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        lengths = update_length(lengths)\n",
    "\n",
    "        with autocast('cuda'):\n",
    "            y_logit, auxiliary_logit = model(X, lengths)\n",
    "            y_logit = y_logit.permute(1, 0, 2)\n",
    "            auxiliary_logit = auxiliary_logit.permute(1, 0, 2)\n",
    "\n",
    "            if y_logit.isnan().any():\n",
    "                print(\"⚠️ ABORT! NaN found in y_logit!\")\n",
    "                break\n",
    "            y_length = torch.count_nonzero(y, axis=1)\n",
    "            \n",
    "            # Main CTC loss\n",
    "            ctc_probs = y_logit.log_softmax(-1)\n",
    "            ctc_probs_length = torch.full(\n",
    "                size=(y.shape[0],),         \n",
    "                fill_value=y_logit.size(0),\n",
    "                dtype=torch.long\n",
    "            )\n",
    "            main_loss = loss_fn(ctc_probs, y, ctc_probs_length, y_length)\n",
    "            \n",
    "            # Auxiliary CTC loss\n",
    "            aux_ctc_probs = auxiliary_logit.log_softmax(-1)\n",
    "            aux_ctc_probs_length = torch.full(\n",
    "                size=(y.shape[0],),         \n",
    "                fill_value=auxiliary_logit.size(0),\n",
    "                dtype=torch.long\n",
    "            )\n",
    "            aux_loss = loss_fn(aux_ctc_probs, y, aux_ctc_probs_length, y_length)\n",
    "            \n",
    "            # Combined loss\n",
    "            loss = main_loss + aux_loss\n",
    "            batch_loss = loss.item()\n",
    "            train_loss += batch_loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = torch.argmax(y_logit.permute(1, 0, 2), dim=2)\n",
    "        total_correct_wer += wer(decode_target(y), decode_pred(y_pred, lengths))\n",
    "\n",
    "        avg_loss = train_loss / (batch_idx + 1)\n",
    "        progress_bar.set_postfix(batch_loss=f\"{batch_loss:.4f}\", avg_loss=f\"{avg_loss:.4f}\")\n",
    "\n",
    "        del X, y, y_logit, auxiliary_logit, loss, y_pred\n",
    "\n",
    "    acc_wer = (total_correct_wer / len(dataloader)) * 100\n",
    "    avg_loss = train_loss / len(dataloader)\n",
    "\n",
    "    print(f\"Epoch {epoch} | Train Loss: {avg_loss:.4f} | Train WER: {acc_wer:.2f}%\")\n",
    "    return avg_loss, acc_wer\n",
    "\n",
    "\n",
    "\n",
    "def test_step(model, loss_fn, epoch, dataloader, scheduler, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    test_loss, total_correct_wer = 0, 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch} (Eval)\", dynamic_ncols=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X, y, lengths) in enumerate(progress_bar):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            lengths = update_length(lengths)\n",
    "\n",
    "            with autocast('cuda'):\n",
    "                y_logit, auxiliary_logit = model(X, lengths)\n",
    "                y_logit = y_logit.permute(1, 0, 2)\n",
    "                auxiliary_logit = auxiliary_logit.permute(1, 0, 2)\n",
    "\n",
    "                if y_logit.isnan().any():\n",
    "                    print(\"⚠️ ABORT! NaN found in y_logit!\")\n",
    "                    break\n",
    "\n",
    "                y_length = torch.count_nonzero(y, axis=1)\n",
    "                \n",
    "                # Main CTC loss\n",
    "                ctc_probs = y_logit.log_softmax(-1)\n",
    "                ctc_probs_length = torch.full(\n",
    "                    size=(y.shape[0],),         \n",
    "                    fill_value=y_logit.size(0),\n",
    "                    dtype=torch.long\n",
    "                )\n",
    "                main_loss = loss_fn(ctc_probs, y, ctc_probs_length, y_length)\n",
    "                \n",
    "                # Auxiliary CTC loss\n",
    "                aux_ctc_probs = auxiliary_logit.log_softmax(-1)\n",
    "                aux_ctc_probs_length = torch.full(\n",
    "                    size=(y.shape[0],),         \n",
    "                    fill_value=auxiliary_logit.size(0),\n",
    "                    dtype=torch.long\n",
    "                )\n",
    "                aux_loss = loss_fn(aux_ctc_probs, y, aux_ctc_probs_length, y_length)\n",
    "                \n",
    "                # Combined loss\n",
    "                loss = main_loss + aux_loss\n",
    "                batch_loss = loss.item()\n",
    "                test_loss += batch_loss\n",
    "\n",
    "            y_pred = torch.argmax(y_logit.permute(1, 0, 2), dim=2)\n",
    "            total_correct_wer += wer(decode_target(y), decode_pred(y_pred, lengths))\n",
    "\n",
    "            avg_loss = test_loss / (batch_idx + 1)\n",
    "            progress_bar.set_postfix(batch_loss=f\"{batch_loss:.4f}\", avg_loss=f\"{avg_loss:.4f}\")\n",
    "\n",
    "            del X, y, y_logit, auxiliary_logit, loss, y_pred\n",
    "\n",
    "    acc_wer = (total_correct_wer / len(dataloader)) * 100\n",
    "    avg_loss = test_loss / len(dataloader)\n",
    "\n",
    "    if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "        scheduler.step(avg_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch} | Test Loss: {avg_loss:.4f} | Test WER: {acc_wer:.2f}%\")\n",
    "    return avg_loss, acc_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "182ac8db",
   "metadata": {
    "id": "af3e3e50",
    "papermill": {
     "duration": 0.018856,
     "end_time": "2025-08-14T05:19:39.642590",
     "exception": false,
     "start_time": "2025-08-14T05:19:39.623734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ViViT_SLR(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vit_model,\n",
    "                 vocab_size=len(idx_to_word),\n",
    "                 batch_first=True,\n",
    "                 input_size=640,\n",
    "                 hidden_size=1024,\n",
    "                 num_layers=2,\n",
    "                 layer_norm_eps=1e-06,\n",
    "                 dropout=0.1,\n",
    "                 frame=max_frames,\n",
    "                 pad_token=0,\n",
    "                 max_pred=64,\n",
    "                 ):\n",
    "\n",
    "        super(ViViT_SLR, self).__init__()\n",
    "\n",
    "        self.vit = vit_model\n",
    "\n",
    "        self.norm_encoding = nn.LayerNorm(input_size, eps=layer_norm_eps)\n",
    "\n",
    "        self.temporal_conv = nn.Sequential(\n",
    "            nn.Conv1d(640, hidden_size, kernel_size=5),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "\n",
    "            # nn.Conv1d(hidden_size, hidden_size, kernel_size=5),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(dropout),\n",
    "            # nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.auxiliary_fc =  nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.pad_token = pad_token\n",
    "        self.frame = frame\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=batch_first, \n",
    "            dropout=dropout, \n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_size*2, vocab_size)\n",
    "\n",
    "        self.max_pred = max_pred\n",
    "    #     self._init_weights()\n",
    "\n",
    "    \n",
    "    # def _init_weights(self):\n",
    "    #     \"\"\"Initialize weights using best practices for different layer types\"\"\"\n",
    "        \n",
    "    #     # Initialize Conv1d layers\n",
    "    #     for module in self.temporal_conv.modules():\n",
    "    #         if isinstance(module, nn.Conv1d):\n",
    "    #             # Kaiming initialization for ReLU activations\n",
    "    #             nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "    #             if module.bias is not None:\n",
    "    #                 nn.init.constant_(module.bias, 0)\n",
    "    #         elif isinstance(module, nn.BatchNorm1d):\n",
    "    #             nn.init.constant_(module.weight, 1)\n",
    "    #             nn.init.constant_(module.bias, 0)\n",
    "        \n",
    "    #     # Initialize LSTM layers\n",
    "    #     for name, param in self.lstm.named_parameters():\n",
    "    #         if 'weight_ih' in name:\n",
    "    #             # Input-hidden weights: Xavier uniform\n",
    "    #             nn.init.xavier_uniform_(param.data)\n",
    "    #         elif 'weight_hh' in name:\n",
    "    #             # Hidden-hidden weights: Orthogonal\n",
    "    #             nn.init.orthogonal_(param.data)\n",
    "    #         elif 'bias' in name:\n",
    "    #             # Initialize biases to zero, except forget gate bias\n",
    "    #             nn.init.constant_(param.data, 0)\n",
    "    #             # Set forget gate bias to 1 (helps with gradient flow)\n",
    "    #             n = param.size(0)\n",
    "    #             param.data[n//4:n//2].fill_(1.0)\n",
    "        \n",
    "    #     # Initialize LayerNorm\n",
    "    #     nn.init.constant_(self.norm_encoding.weight, 1)\n",
    "    #     nn.init.constant_(self.norm_encoding.bias, 0)\n",
    "        \n",
    "    #     # Initialize final linear layer\n",
    "    #     nn.init.xavier_uniform_(self.fc_out.weight)\n",
    "    #     nn.init.constant_(self.fc_out.bias, 0)\n",
    "\n",
    "    #     nn.init.xavier_uniform_(self.auxiliary_fc.weight)\n",
    "    #     nn.init.constant_(self.auxiliary_fc.bias, 0)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, vid, lengths):\n",
    "        \n",
    "        B, T, C, H, W = vid.shape\n",
    "        encoded_output = self.vit(vid.view(B*T, C, H, W)).pooler_output  # (B*T, 768)\n",
    "        encoded_output = encoded_output.view(B, T, 640)  # (B, T, 768)\n",
    "        encoded_output = self.norm_encoding(encoded_output)\n",
    "        encoded_output = self.temporal_conv(encoded_output.permute(0,2,1)).permute(0,2,1)\n",
    "\n",
    "        auxiliary = self.auxiliary_fc(encoded_output)\n",
    "\n",
    "        new_T = encoded_output.size(1)\n",
    "\n",
    "        packed_input = nn.utils.rnn.pack_padded_sequence(\n",
    "            encoded_output,\n",
    "            lengths.cpu(), \n",
    "            batch_first=True,\n",
    "            enforce_sorted=False \n",
    "        )\n",
    "\n",
    "        packed_output, _ = self.lstm(packed_input)  # (B, T, hidden_size * 2)\n",
    "\n",
    "        decoded_output, _ = nn.utils.rnn.pad_packed_sequence(\n",
    "            packed_output,\n",
    "            batch_first=True,\n",
    "            total_length=new_T \n",
    "        )\n",
    "\n",
    "        logits = self.fc_out(self.dropout(decoded_output))  # (B, T, vocab_size)\n",
    "        return logits, auxiliary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "658d62ee-9524-4070-a834-f04e1ca9f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_groups(model: ViViT_SLR, base_lr=5e-5, new_lr=1e-4, weight_decay=0.01):\n",
    "    pretrained_params = []\n",
    "    new_params = []\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue\n",
    "\n",
    "        # Identify newly added components based on naming\n",
    "        if any(\n",
    "            key in name for key in [\n",
    "                \"norm_encoding\", \"fc_out\", \"lstm\", \"temporal_conv\"\n",
    "            ]\n",
    "        ):\n",
    "            new_params.append(param)\n",
    "        else:\n",
    "            pretrained_params.append(param)\n",
    "\n",
    "    print(f\"Pretrained params: {len(pretrained_params)}\")\n",
    "    print(f\"Newly initialized params: {len(new_params)}\")\n",
    "\n",
    "\n",
    "    return [\n",
    "        {\"params\": pretrained_params, \"lr\": base_lr, \"weight_decay\": weight_decay},\n",
    "        {\"params\": new_params, \"lr\": new_lr, \"weight_decay\": weight_decay},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50996d10",
   "metadata": {
    "id": "77d074fe",
    "outputId": "9891d8b8-0d85-4a86-f1ed-f6a641b139e7",
    "papermill": {
     "duration": 21.831456,
     "end_time": "2025-08-14T05:20:01.536799",
     "exception": false,
     "start_time": "2025-08-14T05:19:39.705343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = \"cuda\"\n",
    "\n",
    "vit_model = AutoModel.from_pretrained(\"apple/mobilevit-small\", use_safetensors=True)\n",
    "\n",
    "# peft_config = LoraConfig(\n",
    "#     r=16,\n",
    "#     lora_alpha=32,\n",
    "#     target_modules=[\n",
    "#         \"attention.attention.query\",\n",
    "#         \"attention.attention.key\", \n",
    "#         \"attention.attention.value\",\n",
    "#         \"attention.output.dense\"\n",
    "#     ],\n",
    "#     lora_dropout=0.1,\n",
    "#     bias=\"none\"\n",
    "# )\n",
    "\n",
    "# vit_model = get_peft_model(vit_model, peft_config)\n",
    "# vit_model.print_trainable_parameters()\n",
    "\n",
    "model = ViViT_SLR(vit_model=vit_model).to(device)\n",
    "\n",
    "# model = nn.DataParallel(model)\n",
    "\n",
    "# checkpoint = torch.load(f=\"/home/jovyan/A_folder/Mobile_ViT_LSTM_15_epochs_40.83_wer.pth\")\n",
    "# new_state_dict = checkpoint[\"model_state_dict\"]\n",
    "# model.load_state_dict(new_state_dict, strict=True)\n",
    "# print(\"Loaded checkpoint weights!\")\n",
    "\n",
    "loss_fn = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)\n",
    "# param_groups = get_param_groups(model)\n",
    "# optimizer = torch.optim.AdamW(param_groups)\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(),\n",
    "                            lr=1e-4,\n",
    "                            weight_decay=1e-3)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "# optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "# scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
    "\n",
    "# del checkpoint, new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5e91a9f",
   "metadata": {
    "id": "f18f767f",
    "outputId": "8349d200-c1cd-43f0-80d8-2b6aaedf33e9",
    "papermill": {
     "duration": 23157.143853,
     "end_time": "2025-08-14T11:45:58.692108",
     "exception": false,
     "start_time": "2025-08-14T05:20:01.548255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running from 1 to 50\n",
      "Ready to train!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2836/2836 [19:32<00:00,  2.42it/s, avg_loss=10.5342, batch_loss=8.1039] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 10.5342 | Train WER: 95.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Eval): 100%|██████████| 315/315 [01:52<00:00,  2.81it/s, avg_loss=7.2001, batch_loss=10.6171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Test Loss: 7.2001 | Test WER: 88.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2836/2836 [19:57<00:00,  2.37it/s, avg_loss=7.5344, batch_loss=6.9921] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 7.5344 | Train WER: 82.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 (Eval): 100%|██████████| 315/315 [01:50<00:00,  2.85it/s, avg_loss=6.1280, batch_loss=9.2853] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Test Loss: 6.1280 | Test WER: 67.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2836/2836 [19:24<00:00,  2.44it/s, avg_loss=6.6162, batch_loss=6.1228] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 6.6162 | Train WER: 69.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (Eval): 100%|██████████| 315/315 [01:49<00:00,  2.87it/s, avg_loss=5.0982, batch_loss=7.7615] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Test Loss: 5.0982 | Test WER: 57.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2836/2836 [18:57<00:00,  2.49it/s, avg_loss=5.9019, batch_loss=3.4549] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 5.9019 | Train WER: 58.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 (Eval): 100%|██████████| 315/315 [01:55<00:00,  2.72it/s, avg_loss=4.8434, batch_loss=7.7914] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Test Loss: 4.8434 | Test WER: 51.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2836/2836 [20:17<00:00,  2.33it/s, avg_loss=5.6021, batch_loss=5.8323] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 5.6021 | Train WER: 54.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 (Eval): 100%|██████████| 315/315 [02:01<00:00,  2.59it/s, avg_loss=4.8587, batch_loss=8.4526] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Test Loss: 4.8587 | Test WER: 49.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2836/2836 [19:43<00:00,  2.40it/s, avg_loss=5.5356, batch_loss=3.9934] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 5.5356 | Train WER: 52.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 (Eval): 100%|██████████| 315/315 [01:55<00:00,  2.74it/s, avg_loss=4.5863, batch_loss=9.6499] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Test Loss: 4.5863 | Test WER: 44.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 2836/2836 [20:51<00:00,  2.27it/s, avg_loss=4.8595, batch_loss=3.8833] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 4.8595 | Train WER: 42.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 (Eval): 100%|██████████| 315/315 [02:03<00:00,  2.56it/s, avg_loss=4.1697, batch_loss=7.3583] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Test Loss: 4.1697 | Test WER: 42.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 2836/2836 [20:51<00:00,  2.27it/s, avg_loss=4.5204, batch_loss=3.1538] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 4.5204 | Train WER: 37.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 (Eval): 100%|██████████| 315/315 [02:01<00:00,  2.59it/s, avg_loss=4.1473, batch_loss=6.5216] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Test Loss: 4.1473 | Test WER: 40.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2836/2836 [21:13<00:00,  2.23it/s, avg_loss=4.3954, batch_loss=5.8803] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 4.3954 | Train WER: 36.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 (Eval): 100%|██████████| 315/315 [02:02<00:00,  2.57it/s, avg_loss=4.1044, batch_loss=6.9591] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Test Loss: 4.1044 | Test WER: 39.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 2836/2836 [20:40<00:00,  2.29it/s, avg_loss=4.2432, batch_loss=5.0858] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 4.2432 | Train WER: 34.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 (Eval): 100%|██████████| 315/315 [02:04<00:00,  2.53it/s, avg_loss=4.4698, batch_loss=6.9090] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Test Loss: 4.4698 | Test WER: 47.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 2836/2836 [20:51<00:00,  2.27it/s, avg_loss=4.1701, batch_loss=2.6646] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 4.1701 | Train WER: 34.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 (Eval): 100%|██████████| 315/315 [02:04<00:00,  2.53it/s, avg_loss=4.0700, batch_loss=7.9002] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Test Loss: 4.0700 | Test WER: 37.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 2836/2836 [20:49<00:00,  2.27it/s, avg_loss=3.7028, batch_loss=5.5184] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 3.7028 | Train WER: 28.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 (Eval): 100%|██████████| 315/315 [01:58<00:00,  2.66it/s, avg_loss=4.0420, batch_loss=7.1870] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Test Loss: 4.0420 | Test WER: 37.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 2836/2836 [20:18<00:00,  2.33it/s, avg_loss=3.6704, batch_loss=6.5794] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 3.6704 | Train WER: 28.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 (Eval): 100%|██████████| 315/315 [02:03<00:00,  2.55it/s, avg_loss=3.9754, batch_loss=7.8791] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Test Loss: 3.9754 | Test WER: 36.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 (Eval): 100%|██████████| 315/315 [01:53<00:00,  2.77it/s, avg_loss=4.0720, batch_loss=7.9206] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Test Loss: 4.0720 | Test WER: 37.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 2836/2836 [20:08<00:00,  2.35it/s, avg_loss=3.1913, batch_loss=1.9976] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 3.1913 | Train WER: 23.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 (Eval): 100%|██████████| 315/315 [01:59<00:00,  2.64it/s, avg_loss=4.1408, batch_loss=8.1095] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Test Loss: 4.1408 | Test WER: 37.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 2836/2836 [20:00<00:00,  2.36it/s, avg_loss=3.2808, batch_loss=2.1782] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 3.2808 | Train WER: 25.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 (Eval): 100%|██████████| 315/315 [01:57<00:00,  2.68it/s, avg_loss=4.0330, batch_loss=7.8001] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Test Loss: 4.0330 | Test WER: 37.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 2836/2836 [19:44<00:00,  2.39it/s, avg_loss=2.7249, batch_loss=1.5035] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 2.7249 | Train WER: 17.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 (Eval): 100%|██████████| 315/315 [01:51<00:00,  2.83it/s, avg_loss=4.0667, batch_loss=7.2700] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Test Loss: 4.0667 | Test WER: 35.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 2836/2836 [20:20<00:00,  2.32it/s, avg_loss=2.5808, batch_loss=5.4576] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 2.5808 | Train WER: 16.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 (Eval): 100%|██████████| 315/315 [01:51<00:00,  2.82it/s, avg_loss=4.1068, batch_loss=8.2506] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Test Loss: 4.1068 | Test WER: 36.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 2836/2836 [20:06<00:00,  2.35it/s, avg_loss=2.5844, batch_loss=1.7670] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 2.5844 | Train WER: 15.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 (Eval): 100%|██████████| 315/315 [01:55<00:00,  2.72it/s, avg_loss=4.1687, batch_loss=8.9115] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Test Loss: 4.1687 | Test WER: 35.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 2836/2836 [20:05<00:00,  2.35it/s, avg_loss=2.3677, batch_loss=3.1953] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 2.3677 | Train WER: 13.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 (Eval): 100%|██████████| 315/315 [01:56<00:00,  2.71it/s, avg_loss=4.1202, batch_loss=8.4271] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Test Loss: 4.1202 | Test WER: 36.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21:  36%|███▌      | 1010/2836 [07:22<13:19,  2.28it/s, avg_loss=2.2953, batch_loss=2.9510]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m log\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch | Train loss | Train WER | Test loss | Test WER\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start, epochs):\n\u001b[0;32m---> 18\u001b[0m     train_loss, train_wer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     test_loss, test_wer \u001b[38;5;241m=\u001b[39m test_step(\n\u001b[1;32m     27\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     28\u001b[0m         loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m         scheduler\u001b[38;5;241m=\u001b[39mscheduler\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     33\u001b[0m     log\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_wer\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_wer\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 40\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, optimizer, dataloader, loss_fn, epoch, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m lengths \u001b[38;5;241m=\u001b[39m update_length(lengths)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 40\u001b[0m     y_logit, auxiliary_logit \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     y_logit \u001b[38;5;241m=\u001b[39m y_logit\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     42\u001b[0m     auxiliary_logit \u001b[38;5;241m=\u001b[39m auxiliary_logit\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[20], line 113\u001b[0m, in \u001b[0;36mViViT_SLR.forward\u001b[0;34m(self, vid, lengths)\u001b[0m\n\u001b[1;32m    109\u001b[0m auxiliary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauxiliary_fc(encoded_output)\n\u001b[1;32m    111\u001b[0m new_T \u001b[38;5;241m=\u001b[39m encoded_output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 113\u001b[0m packed_input \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpack_padded_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoded_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlengths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43menforce_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m packed_output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(packed_input)  \u001b[38;5;66;03m# (B, T, hidden_size * 2)\u001b[39;00m\n\u001b[1;32m    122\u001b[0m decoded_output, _ \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mpad_packed_sequence(\n\u001b[1;32m    123\u001b[0m     packed_output,\n\u001b[1;32m    124\u001b[0m     batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m     total_length\u001b[38;5;241m=\u001b[39mnew_T \n\u001b[1;32m    126\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/utils/rnn.py:334\u001b[0m, in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     lengths, sorted_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msort(lengths, descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 334\u001b[0m     sorted_indices \u001b[38;5;241m=\u001b[39m \u001b[43msorted_indices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mindex_select(batch_dim, sorted_indices)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "current = 0\n",
    "num_epochs = 50\n",
    "\n",
    "start = 1 + current\n",
    "epochs = num_epochs + current + 1\n",
    "\n",
    "print(f\"Running from {start} to {epochs-1}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "print(\"Ready to train!!\")\n",
    "\n",
    "log = open('Mobile_ViT_LSTM_readings_aux-loss.txt', 'w')\n",
    "log.write('Epoch | Train loss | Train WER | Test loss | Test WER\\n')\n",
    "\n",
    "for epoch in range(start, epochs):\n",
    "    train_loss, train_wer = train_step(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        epoch=epoch,\n",
    "        dataloader=train_dataloader\n",
    "    )\n",
    "\n",
    "    test_loss, test_wer = test_step(\n",
    "        model=model,\n",
    "        loss_fn=loss_fn,\n",
    "        epoch=epoch,\n",
    "        dataloader=test_dataloader,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "    log.write(f'{epoch} | {train_loss:.4f} | {train_wer:.2f}% | {test_loss:.4f} | {test_wer:.2f}%\\n')\n",
    "    if epoch%5==0:\n",
    "        checkpoint = {\n",
    "            \"model_state_dict\" : model.state_dict(),\n",
    "            \"train_wer\" : train_wer,\n",
    "            \"test_wer\" : test_wer,\n",
    "            \"train_loss\" : train_loss,\n",
    "            \"test_loss\" : test_loss,\n",
    "            \"epoch\" : epoch,\n",
    "            \"optimizer\" : optimizer.state_dict(),\n",
    "            \"scheduler\" : scheduler.state_dict()\n",
    "        }\n",
    "        torch.save(obj=checkpoint, f=f\"Mobile_ViT_LSTM_{epoch}_epochs_{test_wer:.2f}_wer.pth\")\n",
    "        del checkpoint\n",
    "\n",
    "log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7daa6c",
   "metadata": {
    "id": "a37b4a93",
    "papermill": {
     "duration": 0.023262,
     "end_time": "2025-08-14T11:45:58.739373",
     "exception": false,
     "start_time": "2025-08-14T11:45:58.716111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    \"model_state_dict\" : model.state_dict(),\n",
    "    \"train_wer\" : train_wer,\n",
    "    \"test_wer\" : test_wer,\n",
    "    \"train_loss\" : train_loss,\n",
    "    \"test_loss\" : test_loss,\n",
    "    \"epoch\" : epochs-1,\n",
    "    \"optimizer\" : optimizer.state_dict(),\n",
    "    \"scheduler\" : scheduler.state_dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd8975",
   "metadata": {
    "papermill": {
     "duration": 4.987205,
     "end_time": "2025-08-14T11:46:03.737684",
     "exception": false,
     "start_time": "2025-08-14T11:45:58.750479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(obj=checkpoint, f=f\"Mobile_ViT_LSTM_{epochs-1}_epochs.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd32535-3d38-46d3-9fbe-36f407d13b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7372690,
     "sourceId": 11744535,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7784675,
     "sourceId": 12348338,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 478574,
     "modelInstanceId": 462781,
     "sourceId": 615744,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23247.947084,
   "end_time": "2025-08-14T11:46:07.775190",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-14T05:18:39.828106",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1c94be93688344ceb1ac97eef10c58a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ccbf7f1fb0854cca9b95113a7985241a",
       "placeholder": "​",
       "style": "IPY_MODEL_8aa47a4818314c3c96d341d580b10c57",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: "
      }
     },
     "525f94c1bdc540a39d649028ac8e7656": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "52a7816038b24dc6903c5016d6989c7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b03c14ac66ca4e5f88ae5866997d66a9",
       "placeholder": "​",
       "style": "IPY_MODEL_e50f86a0c8f544e186776caef3e2cda0",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "67a0adfa226a4c03b396f45b8e2c71fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_966998a8e4e845adba0f8f02f44b3946",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ce4a55cddfb548cc9f62683c2051041f",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "70f128a3b8944ee68a7e020f85279a23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_52a7816038b24dc6903c5016d6989c7c",
        "IPY_MODEL_c03815254d8c454599ab7b6a45d67f22",
        "IPY_MODEL_c4b23194178447cdb5fa7e1cdfd786bf"
       ],
       "layout": "IPY_MODEL_525f94c1bdc540a39d649028ac8e7656",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7d1f4e6a981a46639a109518335b6486": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8aa47a4818314c3c96d341d580b10c57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8d28474b48e843228725399e1a825e29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "966998a8e4e845adba0f8f02f44b3946": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "b03c14ac66ca4e5f88ae5866997d66a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b3bd428ca17a49f8b94f464ea8aaa555": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c03815254d8c454599ab7b6a45d67f22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fc614113e9b84f86b97576b22c9386bc",
       "max": 346293852,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b3bd428ca17a49f8b94f464ea8aaa555",
       "tabbable": null,
       "tooltip": null,
       "value": 346293852
      }
     },
     "c116976ff6db41c287396c3de1f1f656": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d06b1e22dd3644b5b1760c5ad25e3256",
       "placeholder": "​",
       "style": "IPY_MODEL_f7074c8045224b99b944007418f88318",
       "tabbable": null,
       "tooltip": null,
       "value": " 69.7k/? [00:00&lt;00:00, 6.52MB/s]"
      }
     },
     "c4b23194178447cdb5fa7e1cdfd786bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7d1f4e6a981a46639a109518335b6486",
       "placeholder": "​",
       "style": "IPY_MODEL_8d28474b48e843228725399e1a825e29",
       "tabbable": null,
       "tooltip": null,
       "value": " 346M/346M [00:02&lt;00:00, 259MB/s]"
      }
     },
     "c6a2897159d74b278c7abeb62775b58d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ccbf7f1fb0854cca9b95113a7985241a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce4a55cddfb548cc9f62683c2051041f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d06b1e22dd3644b5b1760c5ad25e3256": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ddf1f0a132d44824a2104f8443b5ff8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1c94be93688344ceb1ac97eef10c58a7",
        "IPY_MODEL_67a0adfa226a4c03b396f45b8e2c71fd",
        "IPY_MODEL_c116976ff6db41c287396c3de1f1f656"
       ],
       "layout": "IPY_MODEL_c6a2897159d74b278c7abeb62775b58d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e50f86a0c8f544e186776caef3e2cda0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f7074c8045224b99b944007418f88318": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fc614113e9b84f86b97576b22c9386bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
